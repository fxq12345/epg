import requests
import random
import time
import re
import os
from bs4 import BeautifulSoup
from datetime import datetime, timedelta

# æ½åŠé¢‘é“é…ç½®ï¼ˆé…·9ä¸“å±ï¼šçº¯æ•°å­—IDï¼‰
weifang_channels = [
    {"id": "1001", "name": "æ½åŠæ–°é—»ç»¼åˆé¢‘é“", "url": "https://m.tvsou.com/epg/db502561//"},
    {"id": "1002", "name": "æ½åŠç”Ÿæ´»é¢‘é“", "url": "https://m.tvsou.com/epg/db502563/"},
    {"id": "1003", "name": "æ½åŠå…¬å…±é¢‘é“", "url": "https://m.tvsou.com/epg/db502562/"},
    {"id": "1004", "name": "æ½åŠç§‘æ•™é¢‘é“", "url": "https://m.tvsou.com/epg/db502564/"}
]

def get_current_date():
    return datetime.now().date().strftime("%Y-%m-%d")

def crawl_channel_epg(channel):
    epg_data = []
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "zh-CN,zh;q=0.9",
        "Referer": "https://m.tvsou.com/"
    }
    current_date = get_current_date()
    try:
        print(f"ğŸ“… {channel['name']}ï¼ˆIDï¼š{channel['id']}ï¼‰- çˆ¬å–æ—¥æœŸï¼š{current_date}")
        response = requests.get(channel["url"], headers=headers, timeout=20, allow_redirects=True)
        response.raise_for_status()
        response.encoding = response.apparent_encoding or "utf-8"
        soup = BeautifulSoup(response.text, "html.parser")
        
        program_container = soup.find("div", class_="epg-list")
        if not program_container:
            print(f"âš ï¸  æœªæ‰¾åˆ°{channel['name']}çš„èŠ‚ç›®å®¹å™¨")
            return epg_data
        
        program_items = program_container.find_all("li", class_="epg-item")
        if not program_items:
            print(f"âš ï¸  {channel['name']}æš‚æ— å…¬å¼€èŠ‚ç›®æ•°æ®")
            return epg_data
        
        for item in program_items:
            time_elem = item.find("span", class_="epg-time")
            title_elem = item.find("span", class_="epg-name")
            if time_elem and title_elem:
                time_str = time_elem.text.strip()
                title = title_elem.text.strip()
                if re.match(r"^\d{2}:\d{2}$", time_str) and title:
                    try:
                        start_time = datetime.strptime(f"{current_date} {time_str}", "%Y-%m-%d %H:%M")
                        epg_data.append({
                            "channel_id": channel["id"],
                            "start": start_time.strftime("%Y%m%d%H%M%S +0800"),
                            "title": title
                        })
                    except ValueError:
                        continue
        
        time.sleep(1.5 + random.random() * 2)
        print(f"ğŸ“Š çˆ¬å–å®Œæˆï¼š{len(epg_data)}æ¡èŠ‚ç›®\n")
    except requests.exceptions.RequestException as e:
        print(f"âŒ {channel['name']}ç½‘ç»œé”™è¯¯ï¼š{str(e)}\n")
    except Exception as e:
        print(f"âŒ {channel['name']}çˆ¬å–å¼‚å¸¸ï¼š{str(e)}\n")
    return epg_data

def generate_xmltv_file(epg_data, channels):
    import xml.etree.ElementTree as ET
    from xml.dom import minidom
    tv = ET.Element("tv", {
        "source-info-url": "https://m.tvsou.com",
        "source-info-name": "TVSou-æ½åŠEPGï¼ˆé…·9é€‚é…ï¼‰",
        "generated-date": datetime.now().strftime("%Y%m%d%H%M%S +0800"),
        "generator-info-name": "WeifangEPGCrawler-Ku9"
    })
    
    for channel in channels:
        chan_elem = ET.SubElement(tv, "channel", {"id": channel["id"]})
        ET.SubElement(chan_elem, "display-name").text = channel["name"]
        ET.SubElement(chan_elem, "icon", {"src": f"https://icon.tvsou.com/{channel['id']}.png"})
    
    for prog in epg_data:
        prog_elem = ET.SubElement(tv, "programme", {
            "start": prog["start"],
            "channel": prog["channel_id"]
        })
        ET.SubElement(prog_elem, "title", {"lang": "zh"}).text = prog["title"]
    
    os.makedirs("output", exist_ok=True)
    xml_str = minidom.parseString(ET.tostring(tv)).toprettyxml(indent="  ")
    xml_str = "\n".join([line for line in xml_str.split("\n") if line.strip()])
    output_path = "output/weifang.xml"
    
    # é…·9é€‚é…ï¼šä¿å­˜ä¸ºGBKç¼–ç 
    with open(output_path, "w", encoding="gbk") as f:
        f.write(xml_str)
    
    print(f"ğŸ‰ æ½åŠEPGç”Ÿæˆå®Œæˆï¼ˆé…·9é€‚é…ï¼‰ï¼š{output_path}ï¼ˆå…±{len(epg_data)}æ¡èŠ‚ç›®ï¼‰")

if __name__ == "__main__":
    all_epg = []
    print("="*60 + "\næ½åŠæœè§†ç½‘EPGçˆ¬è™«ï¼ˆé…·9é€‚é…ï¼‰å¯åŠ¨\n" + "="*60)
    for channel in weifang_channels:
        all_epg.extend(crawl_channel_epg(channel))
    if all_epg:
        generate_xmltv_file(all_epg, weifang_channels)
    else:
        print("âš ï¸  æœªçˆ¬å–åˆ°ä»»ä½•èŠ‚ç›®æ•°æ®ï¼Œç”Ÿæˆç©ºæ–‡ä»¶é¿å…æŠ¥é”™")
        os.makedirs("output", exist_ok=True)
        with open("output/weifang.xml", "w", encoding="gbk") as f:
            f.write('<tv></tv>')
