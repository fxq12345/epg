import requests
import random
import time
import re
import os
from bs4 import BeautifulSoup
from datetime import datetime, timedelta

# æœè§†ç½‘æ½åŠé¢‘é“é…ç½®ï¼ˆç»éªŒè¯çš„æœ‰æ•ˆé“¾æ¥ï¼‰
weifang_channels = [
    {"id": "SDWF-SDWF1", "name": "æ½åŠæ–°é—»ç»¼åˆé¢‘é“", "url": "https://www.tvsou.com/epg/db502561/"},
    {"id": "SDWF-SDWF3", "name": "æ½åŠç”Ÿæ´»é¢‘é“", "url": "https://www.tvsou.com/epg/db502563/"},
    {"id": "SDWF-SDWF2", "name": "æ½åŠå…¬å…±é¢‘é“", "url": "https://www.tvsou.com/epg/db502562/"},
    {"id": "SDWF-SDWF4", "name": "æ½åŠç§‘æ•™é¢‘é“", "url": "https://www.tvsou.com/epg/db502564/"}
]

def get_current_date():
    """è·å–å½“å‰æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰"""
    return datetime.now().date().strftime("%Y-%m-%d")

def crawl_channel_epg(channel):
    epg_data = []
    # å¼ºåŒ–è¯·æ±‚å¤´ï¼Œé™ä½åçˆ¬æ¦‚ç‡
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "zh-CN,zh;q=0.9",
        "Referer": "https://www.tvsou.com/",
        "Connection": "keep-alive"
    }
    current_date = get_current_date()
    try:
        print(f"ğŸ“… {channel['name']} - çˆ¬å–æ—¥æœŸï¼š{current_date}")
        
        # å‘èµ·è¯·æ±‚ï¼ˆæ”¯æŒé‡å®šå‘ï¼‰
        response = requests.get(channel["url"], headers=headers, timeout=20, allow_redirects=True)
        response.raise_for_status()  # æŠ›å‡ºHTTPé”™è¯¯
        response.encoding = response.apparent_encoding or "utf-8"  # è‡ªåŠ¨é€‚é…ç¼–ç 
        soup = BeautifulSoup(response.text, "html.parser")
        
        # å®šä½èŠ‚ç›®åˆ—è¡¨å®¹å™¨ï¼ˆæœè§†ç½‘æ ¸å¿ƒç»“æ„ï¼‰
        program_container = soup.find("div", class_="epg-list")
        if not program_container:
            print(f"âš ï¸  æœªæ‰¾åˆ°{channel['name']}çš„èŠ‚ç›®å®¹å™¨ï¼Œå¯èƒ½é¡µé¢ç»“æ„å˜æ›´")
            return epg_data
        
        # æå–æ‰€æœ‰èŠ‚ç›®é¡¹
        program_items = program_container.find_all("li", class_="epg-item")
        if not program_items:
            print(f"âš ï¸  {channel['name']}æš‚æ— å…¬å¼€èŠ‚ç›®æ•°æ®")
            return epg_data
        
        # è§£æèŠ‚ç›®æ—¶é—´å’Œæ ‡é¢˜
        for item in program_items:
            time_elem = item.find("span", class_="epg-time")
            title_elem = item.find("span", class_="epg-name")
            
            if time_elem and title_elem:
                time_str = time_elem.text.strip()
                title = title_elem.text.strip()
                
                # è¿‡æ»¤æ— æ•ˆæ•°æ®ï¼ˆæ—¶é—´æ ¼å¼éœ€ä¸ºHH:MMï¼Œæ ‡é¢˜éç©ºï¼‰
                if re.match(r"^\d{2}:\d{2}$", time_str) and title:
                    try:
                        start_time = datetime.strptime(f"{current_date} {time_str}", "%Y-%m-%d %H:%M")
                        epg_data.append({
                            "channel_id": channel["id"],
                            "start": start_time.strftime("%Y%m%d%H%M%S +0800"),
                            "title": title
                        })
                    except ValueError:
                        print(f"âš ï¸  æ— æ•ˆæ—¶é—´æ ¼å¼ï¼š{time_str}ï¼Œå·²è·³è¿‡")
                        continue
        
        # éšæœºå»¶æ—¶é˜²åçˆ¬ï¼ˆ1.5-3.5ç§’ï¼‰
        time.sleep(1.5 + random.random() * 2)
        print(f"ğŸ“Š çˆ¬å–å®Œæˆï¼š{len(epg_data)}æ¡èŠ‚ç›®\n")
    
    except requests.exceptions.RequestException as e:
        print(f"âŒ {channel['name']}ç½‘ç»œé”™è¯¯ï¼š{str(e)}\n")
    except Exception as e:
        print(f"âŒ {channel['name']}çˆ¬å–å¼‚å¸¸ï¼š{str(e)}\n")
    
    return epg_data

def generate_xmltv_file(epg_data, channels):
    """ç”Ÿæˆç¬¦åˆXMLTVæ ‡å‡†çš„æ½åŠEPGæ–‡ä»¶"""
    import xml.etree.ElementTree as ET
    from xml.dom import minidom
    
    # æ ¹èŠ‚ç‚¹é…ç½®
    tv = ET.Element("tv", {
        "source-info-url": "https://www.tvsou.com",
        "source-info-name": "TVSou-æ½åŠEPG",
        "generated-date": datetime.now().strftime("%Y%m%d%H%M%S +0800"),
        "generator-info-name": "WeifangEPGCrawler"
    })
    
    # æ·»åŠ é¢‘é“ä¿¡æ¯
    for channel in channels:
        chan_elem = ET.SubElement(tv, "channel", {"id": channel["id"]})
        ET.SubElement(chan_elem, "display-name").text = channel["name"]
        ET.SubElement(chan_elem, "icon", {"src": f"https://icon.tvsou.com/{channel['id']}.png"})  # å›¾æ ‡å ä½
    
    # æ·»åŠ èŠ‚ç›®ä¿¡æ¯
    for prog in epg_data:
        prog_elem = ET.SubElement(tv, "programme", {
            "start": prog["start"],
            "channel": prog["channel_id"]
        })
        ET.SubElement(prog_elem, "title", {"lang": "zh"}).text = prog["title"]
    
    # ä¿å­˜æ–‡ä»¶
    os.makedirs("output", exist_ok=True)
    xml_str = minidom.parseString(ET.tostring(tv)).toprettyxml(indent="  ")
    xml_str = "\n".join([line for line in xml_str.split("\n") if line.strip()])  # å»é™¤ç©ºè¡Œ
    output_path = "output/weifang.xml"  # ç»Ÿä¸€æ–‡ä»¶åï¼Œä¾¿äºmerge.pyè¯»å–
    
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(xml_str)
    
    print(f"ğŸ‰ æ½åŠEPGç”Ÿæˆå®Œæˆï¼š{output_path}ï¼ˆå…±{len(epg_data)}æ¡èŠ‚ç›®ï¼‰")

if __name__ == "__main__":
    all_epg = []
    print("="*60 + "\næ½åŠæœè§†ç½‘EPGçˆ¬è™«å¯åŠ¨\n" + "="*60)
    
    # æ‰¹é‡çˆ¬å–æ‰€æœ‰é¢‘é“
    for channel in weifang_channels:
        all_epg.extend(crawl_channel_epg(channel))
    
    # ç”ŸæˆXMLæ–‡ä»¶ï¼ˆä»…å½“æœ‰æœ‰æ•ˆæ•°æ®æ—¶ï¼‰
    if all_epg:
        generate_xmltv_file(all_epg, weifang_channels)
    else:
        print("âš ï¸  æœªçˆ¬å–åˆ°æœ‰æ•ˆèŠ‚ç›®æ•°æ®ï¼Œè·³è¿‡æ–‡ä»¶ç”Ÿæˆ")
        # ç”Ÿæˆç©ºæ–‡ä»¶é¿å…merge.pyæŠ¥é”™
        os.makedirs("output", exist_ok=True)
        with open("output/weifang.xml", "w", encoding="utf-8") as f:
            f.write('<tv></tv>')
