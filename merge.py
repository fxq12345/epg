import os
import gzip
import re
import time
import logging
from typing import List, Dict, Set, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import requests
from lxml import etree
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

===================== é…ç½®åŒº =====================
CONFIG_FILE = "config.txt"
OUTPUT_DIR = "output"
LOG_FILE = "epg_merge.log"
MAX_WORKERS = 5  # åŒæ—¶æŠ“å–5æ¡æº
TIMEOUT = 30
CORE_RETRY_COUNT = 2
æœ¬åœ°æ½åŠEPGæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
LOCAL_WEIFANG_EPG = os.path.join(OUTPUT_DIR, "weifang.xml")

é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler()
    ],
    force=True
)
==================================================

class EPGGenerator:
    def init(self):
        self.session = self._create_session()
        self.channel_ids: Set[str] = set()
        self.all_channels: List = []
        self.all_programs: List = []
        self.channel_programs: Dict[str, List] = {}
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        
    def _create_session(self) -> requests.Session:
        session = requests.Session()
        retry_strategy = Retry(
            total=CORE_RETRY_COUNT + 2,
            backoff_factor=1.5,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "application/xml, /",
            "Accept-Encoding": "gzip, deflate"
        })
        return session

    def read_epg_sources(self) -> List[str]:
        if not os.path.exists(CONFIG_FILE):
            logging.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CONFIG_FILE}")
            return []
            
        try:
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                sources = [
                    line.strip() for line_num, line in enumerate(f, 1)
                    if line.strip() and not line.startswith("#") and line.startswith(("http://", "https://"))
                ]
            logging.info(f"ä»{CONFIG_FILE}è¯»å–åˆ°{len(sources)}æ¡EPGæº:")
            for idx, source in enumerate(sources, 1):
                logging.info(f"  {idx}. {source[:60]}...")
            return sources
        except Exception as e:
            logging.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
            return []

    def clean_xml_content(self, content: str) -> str:
        content_clean = re.sub(r'[x00-x08x0Bx0Cx0E-x1Fx7F]', '', content)
        return content_clean.replace('& ', '&amp; ')

    def fetch_single_source(self, source: str) -> Tuple[bool, any]:
        try:
            start_time = time.time()
            response = self.session.get(source, timeout=TIMEOUT)
            response.raise_for_status()
            
            if source.endswith('.gz'):
                content = gzip.decompress(response.content).decode('utf-8')
            else:
                content = response.text
                
            content_clean = self.clean_xml_content(content)
            xml_tree = etree.fromstring(content_clean.encode('utf-8'))
            cost_time = time.time() - start_time
            logging.info(f"âœ… æŠ“å–æˆåŠŸ: {source[:30]}... (è€—æ—¶{cost_time:.2f}s)")
            return True, xml_tree
        except Exception as e:
            logging.error(f"âŒ æŠ“å–å¤±è´¥: {source[:30]}... -> {str(e)[:50]}")
            return False, None

    def process_channels_and_programs(self, xml_tree, source: str):
        channel_count = 0
        for channel in xml_tree.xpath("//channel"):
            channel_id = channel.get("id", "").strip()
            if not channel_id or channel_id in self.channel_ids:
                continue
            self.channel_ids.add(channel_id)
            self.all_channels.append(channel)
            self.channel_programs[channel_id] = []
            channel_count += 1
        
        program_count = 0
        for program in xml_tree.xpath("//programme"):
            channel_id = program.get("channel", "").strip()
            if channel_id and channel_id in self.channel_programs:
                self.channel_programs[channel_id].append(program)
                self.all_programs.append(program)
                program_count += 1
        
        logging.info(f"ğŸ”§ å¤„ç†{source[:30]}...: æ–°å¢é¢‘é“{channel_count}ä¸ªï¼Œæ–°å¢èŠ‚ç›®{program_count}ä¸ª")

    def process_local_weifang_epg(self):
        if not os.path.exists(LOCAL_WEIFANG_EPG):
            logging.warning(f"âš ï¸ æœ¬åœ°æ½åŠEPGæ–‡ä»¶ä¸å­˜åœ¨: {LOCAL_WEIFANG_EPG}ï¼Œè·³è¿‡")
            return
        
        try:
            logging.info(f"å¼€å§‹åˆå¹¶æœ¬åœ°æ½åŠEPGæ–‡ä»¶")
            with open(LOCAL_WEIFANG_EPG, "r", encoding="utf-8") as f:
                content = f.read()
            content_clean = self.clean_xml_content(content)
            xml_tree = etree.fromstring(content_clean.encode('utf-8'))
            self.process_channels_and_programs(xml_tree, "æœ¬åœ°æ½åŠEPG")
            logging.info(f"âœ… æˆåŠŸåˆå¹¶æœ¬åœ°æ½åŠEPG")
        except Exception as e:
            logging.error(f"âŒ åˆå¹¶æœ¬åœ°æ½åŠEPGå¤±è´¥: {str(e)}")

    def fetch_and_process_all_sources(self, sources: List[str]):
        logging.info("nå¼€å§‹æŠ“å–æ‰€æœ‰EPGæº:")
        with ThreadPoolExecutor(max_workers=min(MAX_WORKERS, len(sources))) as executor:
            future_to_source = {executor.submit(self.fetch_single_source, source): source for source in sources}
            for future in as_completed(future_to_source):
                source = future_to_source[future]
                try:
                    success, xml_tree = future.result()
                    if success and xml_tree is not None:
                        self.process_channels_and_programs(xml_tree, source)
                except Exception as e:
                    logging.error(f"å¤„ç†æº{source[:30]}...å¤±è´¥: {str(e)}")
        
        self.process_local_weifang_epg()

    def generate_final_xml(self) -> str:
        xml_declare = f'''
'''
        root = etree.fromstring(f"{xml_declare}".encode("utf-8"))
        
        for channel in self.all_channels:
            root.append(channel)
        for program in self.all_programs:
            root.append(program)
            
        return etree.tostring(root, encoding="utf-8", pretty_print=True).decode("utf-8")

    def save_files(self, xml_content: str):
        xml_path = os.path.join(OUTPUT_DIR, "epg.xml")
        with open(xml_path, "w", encoding="utf-8") as f:
            f.write(xml_content)
        
        gz_path = os.path.join(OUTPUT_DIR, "epg.gz")
        with gzip.open(gz_path, "wb") as f:
            f.write(xml_content.encode("utf-8"))
        
        logging.info(f"nğŸ’¾ æ–‡ä»¶ä¿å­˜æˆåŠŸ:")
        logging.info(f"  - XMLæ–‡ä»¶: {os.path.abspath(xml_path)}")
        logging.info(f"  - GZIPæ–‡ä»¶: {os.path.abspath(gz_path)}")

    def print_statistics(self):
        logging.info("n" + "="*50)
        logging.info("ğŸ“Š EPGåˆå¹¶ç»Ÿè®¡æŠ¥å‘Š")
        logging.info(f"  æ€»é¢‘é“æ•°: {len(self.channel_ids)}")
        logging.info(f"  æ€»èŠ‚ç›®æ•°: {len(self.all_programs)}")
        logging.info("="*50)

    def run(self):
        start_time = time.time()
        logging.info("n" + "="*50)
        logging.info("ğŸš€ å¯åŠ¨EPGåˆå¹¶æµç¨‹")
        logging.info("="*50)
        
        try:
            sources = self.read_epg_sources()
            if not sources:
                logging.error("âŒ æ— å¯ç”¨EPGæºï¼Œæµç¨‹ç»ˆæ­¢")
                return False
            
            self.fetch_and_process_all_sources(sources)
            xml_content = self.generate_final_xml()
            self.save_files(xml_content)
            self.print_statistics()
            
            total_time = time.time() - start_time
            logging.info(f"nâœ… åˆå¹¶æµç¨‹å®Œæˆ! æ€»è€—æ—¶: {total_time:.2f}ç§’")
            return True
        except Exception as e:
            logging.error(f"nğŸ’¥ åˆå¹¶æµç¨‹å¼‚å¸¸å¤±è´¥: {str(e)}", exc_info=True)
            return False

def main():
    generator = EPGGenerator()
    success = generator.run()
    exit(0 if success else 1)

if name == "main":
    main()
