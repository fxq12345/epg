import os
import gzip
import re
import time
import logging
from typing import List, Dict, Set, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
import xml.etree.ElementTree as ET
from xml.dom import minidom

import requests
from lxml import etree
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ===================== é…ç½®åŒº =====================
CONFIG_FILE = "config.txt"
OUTPUT_DIR = "output"
LOG_FILE = "epg_merge.log"
MAX_WORKERS = 3
TIMEOUT = 30
CORE_RETRY_COUNT = 2

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# é«˜æ¸…é¢‘é“åˆ°æ ‡æ¸…é¢‘é“çš„æ˜ å°„ï¼ˆå¦‚æœé«˜æ¸…é¢‘é“æ²¡æœ‰èŠ‚ç›®å•ï¼Œä½¿ç”¨æ ‡æ¸…é¢‘é“èŠ‚ç›®å•ï¼‰
HD_TO_SD_MAPPING = {
    "CCTV1é«˜æ¸…": "CCTV1",
    "CCTV2é«˜æ¸…": "CCTV2", 
    "CCTV3é«˜æ¸…": "CCTV3",
    "CCTV4é«˜æ¸…": "CCTV4",
    "CCTV5é«˜æ¸…": "CCTV5",
    "CCTV6é«˜æ¸…": "CCTV6",
    "CCTV7é«˜æ¸…": "CCTV7",
    "CCTV8é«˜æ¸…": "CCTV8",
    "CCTV9é«˜æ¸…": "CCTV9",
    "CCTV10é«˜æ¸…": "CCTV10",
    "CCTV11é«˜æ¸…": "CCTV11",
    "CCTV12é«˜æ¸…": "CCTV12",
    "CCTV13é«˜æ¸…": "CCTV13",
    "CCTV14é«˜æ¸…": "CCTV14",
    "CCTV15é«˜æ¸…": "CCTV15",
    "CCTV16é«˜æ¸…": "CCTV16",
    "CCTV17é«˜æ¸…": "CCTV17",
    "CCTV4K": "CCTV4",
    "åŒ—äº¬å«è§†4K": "åŒ—äº¬å«è§†",
    "æ¹–å—å«è§†4K": "æ¹–å—å«è§†",
    "æµ™æ±Ÿå«è§†4K": "æµ™æ±Ÿå«è§†",
    "æ±Ÿè‹å«è§†4K": "æ±Ÿè‹å«è§†",
    "ä¸œæ–¹å«è§†4K": "ä¸œæ–¹å«è§†",
    "å¹¿ä¸œå«è§†4K": "å¹¿ä¸œå«è§†",
    "æ·±åœ³å«è§†4K": "æ·±åœ³å«è§†",
    "å±±ä¸œå«è§†4K": "å±±ä¸œå«è§†"
}

# ==================================================

class EPGGenerator:
    def __init__(self):
        self.session = self._create_session()
        self.channel_ids: Set[str] = set()
        self.all_channels: List = []
        self.all_programs: List = []
        self.channel_programs: Dict[str, List] = {}  # é¢‘é“ID -> èŠ‚ç›®åˆ—è¡¨
        
    def _create_session(self) -> requests.Session:
        """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„ä¼šè¯"""
        session = requests.Session()
        retry_strategy = Retry(
            total=CORE_RETRY_COUNT + 2,
            backoff_factor=1.5,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "application/xml, */*",
            "Accept-Encoding": "gzip, deflate"
        })
        return session

    def read_epg_sources(self) -> List[str]:
        """è¯»å–é…ç½®æ–‡ä»¶ä¸­çš„EPGæº"""
        if not os.path.exists(CONFIG_FILE):
            logging.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CONFIG_FILE}")
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {CONFIG_FILE}")
            
        try:
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                sources = []
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if line and not line.startswith("#") and line.startswith(("http://", "https://")):
                        sources.append(line)
                
                logging.info(f"è¯»å–åˆ°{len(sources)}ä¸ªEPGæº")
                for i, source in enumerate(sources, 1):
                    logging.info(f"  {i}. {source}")
                
                return sources
                
        except Exception as e:
            logging.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
            raise

    def clean_xml_content(self, content: str) -> str:
        """æ¸…ç†XMLå†…å®¹"""
        content_clean = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', content)
        content_clean = content_clean.replace('& ', '&amp; ')
        return content_clean

    def fetch_single_source(self, source: str) -> Tuple[bool, any]:
        """è·å–å•ä¸ªEPGæºæ•°æ®"""
        try:
            start_time = time.time()
            logging.info(f"æŠ“å–: {source[:60]}...")
            
            response = self.session.get(source, timeout=TIMEOUT)
            response.raise_for_status()
            
            if source.endswith('.gz'):
                content = gzip.decompress(response.content).decode('utf-8')
            else:
                content = response.text
                
            content_clean = self.clean_xml_content(content)
            xml_tree = etree.fromstring(content_clean.encode('utf-8'))
            
            cost_time = time.time() - start_time
            logging.info(f"æˆåŠŸ: {cost_time:.2f}s")
            return True, xml_tree
            
        except Exception as e:
            logging.error(f"å¤±è´¥: {str(e)[:80]}")
            return False, None

    def process_channels_and_programs(self, xml_tree):
        """å¤„ç†é¢‘é“å’ŒèŠ‚ç›®æ•°æ®"""
        # å¤„ç†é¢‘é“
        channels = xml_tree.xpath("//channel")
        for channel in channels:
            channel_id = channel.get("id", "").strip()
            if not channel_id or channel_id in self.channel_ids:
                continue
                
            self.channel_ids.add(channel_id)
            self.all_channels.append(channel)
            
            # åˆå§‹åŒ–è¯¥é¢‘é“çš„èŠ‚ç›®åˆ—è¡¨
            if channel_id not in self.channel_programs:
                self.channel_programs[channel_id] = []
        
        # å¤„ç†èŠ‚ç›®
        programs = xml_tree.xpath("//programme")
        for program in programs:
            channel_id = program.get("channel", "").strip()
            if channel_id and channel_id in self.channel_programs:
                self.channel_programs[channel_id].append(program)
                self.all_programs.append(program)

    def enhance_hd_channels(self):
        """å¢å¼ºé«˜æ¸…é¢‘é“ï¼šå¦‚æœé«˜æ¸…é¢‘é“æ²¡æœ‰èŠ‚ç›®å•ï¼Œä½¿ç”¨æ ‡æ¸…é¢‘é“çš„èŠ‚ç›®å•"""
        logging.info("ğŸ”§ å¢å¼ºé«˜æ¸…é¢‘é“èŠ‚ç›®å•...")
        enhanced_count = 0
        
        for hd_channel, sd_channel in HD_TO_SD_MAPPING.items():
            # å¦‚æœé«˜æ¸…é¢‘é“å­˜åœ¨ä½†æ²¡æœ‰èŠ‚ç›®å•ï¼Œä¸”æ ‡æ¸…é¢‘é“æœ‰èŠ‚ç›®å•
            if (hd_channel in self.channel_ids and 
                hd_channel not in self.channel_programs and 
                sd_channel in self.channel_programs and 
                self.channel_programs[sd_channel]):
                
                logging.info(f"  âœ… {hd_channel} â† {sd_channel}")
                sd_programs = self.channel_programs[sd_channel]
                
                # å¤åˆ¶æ ‡æ¸…é¢‘é“çš„èŠ‚ç›®å•åˆ°é«˜æ¸…é¢‘é“
                for program in sd_programs:
                    # æ·±æ‹·è´èŠ‚ç›®å…ƒç´ 
                    program_str = etree.tostring(program, encoding='unicode')
                    new_program = etree.fromstring(program_str)
                    new_program.set("channel", hd_channel)
                    self.all_programs.append(new_program)
                    
                self.channel_programs[hd_channel] = [etree.fromstring(etree.tostring(p, encoding='unicode')) 
                                                   for p in sd_programs]
                for p in self.channel_programs[hd_channel]:
                    p.set("channel", hd_channel)
                    
                enhanced_count += 1
        
        logging.info(f"âœ… å¢å¼ºäº†{enhanced_count}ä¸ªé«˜æ¸…é¢‘é“çš„èŠ‚ç›®å•")

    def fetch_and_process_all_sources(self, sources: List[str]) -> bool:
        """è·å–å¹¶å¤„ç†æ‰€æœ‰EPGæº"""
        successful_sources = 0
        
        with ThreadPoolExecutor(max_workers=min(MAX_WORKERS, len(sources))) as executor:
            future_to_source = {executor.submit(self.fetch_single_source, source): source 
                              for source in sources}
            
            for future in as_completed(future_to_source):
                source = future_to_source[future]
                try:
                    success, xml_tree = future.result()
                    if success and xml_tree is not None:
                        self.process_channels_and_programs(xml_tree)
                        successful_sources += 1
                except Exception as e:
                    logging.error(f"å¤„ç†å¤±è´¥ {source}: {str(e)[:80]}")
        
        if successful_sources > 0:
            self.enhance_hd_channels()
            return True
        
        return False

    def generate_final_xml(self) -> str:
        """ç”Ÿæˆæœ€ç»ˆçš„EPG XMLæ–‡ä»¶"""
        xml_declare = f'''<?xml version="1.0" encoding="UTF-8"?>
<tv generator-info-name="EPGåˆå¹¶å™¨" 
    last-update="{datetime.now().strftime('%Y%m%d%H%M%S')}">'''
        
        root = etree.fromstring(f"{xml_declare}</tv>".encode("utf-8"))
        
        # æ·»åŠ æ‰€æœ‰é¢‘é“
        for channel in self.all_channels:
            root.append(channel)
            
        # æ·»åŠ æ‰€æœ‰èŠ‚ç›®å•
        for program in self.all_programs:
            root.append(program)
            
        return etree.tostring(root, encoding="utf-8", pretty_print=True).decode("utf-8")

    def save_files(self, xml_content: str):
        """ä¿å­˜EPGæ–‡ä»¶"""
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        
        # æ¸…ç†æ—§æ–‡ä»¶
        for f in os.listdir(OUTPUT_DIR):
            if f.endswith(('.xml', '.gz')) and os.path.isfile(os.path.join(OUTPUT_DIR, f)):
                try:
                    os.remove(os.path.join(OUTPUT_DIR, f))
                except Exception:
                    pass
        
        # ä¿å­˜XMLæ–‡ä»¶
        xml_path = os.path.join(OUTPUT_DIR, "epg.xml")
        with open(xml_path, "w", encoding="utf-8") as f:
            f.write(xml_content)
        xml_size = os.path.getsize(xml_path) / 1024 / 1024  # MB
        
        # ä¿å­˜GZIPå‹ç¼©æ–‡ä»¶
        gz_path = os.path.join(OUTPUT_DIR, "epg.gz")
        with gzip.open(gz_path, "wb") as f:
            f.write(xml_content.encode("utf-8"))
        gz_size = os.path.getsize(gz_path) / 1024  # KB
        
        logging.info(f"ğŸ’¾ æ–‡ä»¶ä¿å­˜æˆåŠŸ:")
        logging.info(f"  ğŸ“„ epg.xml: {xml_size:.2f} MB")
        logging.info(f"  ğŸ“¦ epg.gz: {gz_size:.1f} KB")

    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        total_channels = len(self.channel_ids)
        total_programs = len(self.all_programs)
        
        # ç»Ÿè®¡é«˜æ¸…é¢‘é“
        hd_channels = [c for c in self.channel_ids if any(x in c for x in ['é«˜æ¸…', '4K', 'HD'])]
        hd_with_programs = len([c for c in hd_channels if c in self.channel_programs and self.channel_programs[c]])
        
        logging.info("\n" + "="*50)
        logging.info("ğŸ“Š EPGç»Ÿè®¡æŠ¥å‘Š")
        logging.info("="*50)
        logging.info(f"æ€»é¢‘é“æ•°: {total_channels}")
        logging.info(f"æ€»èŠ‚ç›®æ•°: {total_programs}")
        logging.info(f"é«˜æ¸…/4Ké¢‘é“: {len(hd_channels)}ä¸ª")
        logging.info(f"æœ‰èŠ‚ç›®å•çš„é«˜æ¸…é¢‘é“: {hd_with_programs}ä¸ª")
        
        # æ˜¾ç¤ºæ²¡æœ‰èŠ‚ç›®å•çš„é¢‘é“
        channels_without_programs = [c for c in self.channel_ids 
                                   if c not in self.channel_programs or not self.channel_programs[c]]
        if channels_without_programs:
            logging.info(f"æ— èŠ‚ç›®å•çš„é¢‘é“: {len(channels_without_programs)}ä¸ª")
            for channel in channels_without_programs[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                logging.info(f"  - {channel}")
        
        logging.info("="*50)

    def run(self):
        """ä¸»è¿è¡Œæ–¹æ³•"""
        start_time = time.time()
        logging.info("ğŸš€ å¼€å§‹EPGåˆå¹¶")
        
        try:
            # è¯»å–EPGæº
            sources = self.read_epg_sources()
            if not sources:
                logging.error("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„EPGæº")
                return False
            
            # è·å–å¹¶å¤„ç†æ‰€æœ‰æº
            if not self.fetch_and_process_all_sources(sources):
                logging.error("âŒ EPGæºè·å–å¤±è´¥")
                return False
                
            # ç”Ÿæˆæœ€ç»ˆXML
            xml_content = self.generate_final_xml()
            
            # ä¿å­˜æ–‡ä»¶
            self.save_files(xml_content)
            
            # æ‰“å°ç»Ÿè®¡
            self.print_statistics()
            
            total_time = time.time() - start_time
            logging.info(f"âœ… å®Œæˆ! è€—æ—¶: {total_time:.2f}ç§’")
            return True
            
        except Exception as e:
            logging.error(f"ğŸ’¥ å¤±è´¥: {str(e)}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*50)
    print("ğŸ“º EPGåˆå¹¶å·¥å…·")
    print("="*50)
    
    generator = EPGGenerator()
    success = generator.run()
    
    if success:
        print("\nâœ… EPGæ–‡ä»¶ç”ŸæˆæˆåŠŸ!")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {os.path.abspath(OUTPUT_DIR)}")
    else:
        print("\nâŒ EPGæ–‡ä»¶ç”Ÿæˆå¤±è´¥!")
    
    exit(0 if success else 1)

if __name__ == "__main__":
    main()
