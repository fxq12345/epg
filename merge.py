import os
import gzip
import re
import time
import logging
from typing import List, Set
from datetime import datetime, timedelta
import requests
from lxml import etree
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ===================== é…ç½®åŒº =====================
CONFIG_FILE = "config.txt"  # ç½‘ç»œæºé…ç½®æ–‡ä»¶
OUTPUT_DIR = "output"
LOG_FILE = "epg_merge.log"
TIMEOUT = 30
# æœ¬åœ°æ½åŠEPGæ–‡ä»¶è·¯å¾„ï¼ˆç”±weifang_epg_spider.pyç”Ÿæˆï¼‰
LOCAL_WEIFANG_EPG = "weifang_epg.xml"
# æ½åŠæœ¬åœ°é¢‘é“é…ç½®ï¼ˆç”¨äºæ ¡éªŒæœ¬åœ°EPGï¼‰
WEIFANG_CHANNELS = [
    {"id": "1001", "name": "æ½åŠæ–°é—»ç»¼åˆé¢‘é“", "alias": "æ½åŠæ–°é—»"},
    {"id": "1002", "name": "æ½åŠç»æµç”Ÿæ´»é¢‘é“", "alias": "æ½åŠç»æµç”Ÿæ´»"},
    {"id": "1003", "name": "æ½åŠå…¬å…±é¢‘é“", "alias": "æ½åŠå…¬å…±"},
    {"id": "1004", "name": "æ½åŠç§‘æ•™æ–‡åŒ–é¢‘é“", "alias": "æ½åŠç§‘æ•™æ–‡åŒ–"},
    {"id": "1008", "name": "å¯¿å…‰è”¬èœé¢‘é“", "alias": "å¯¿å…‰è”¬èœ"},
    {"id": "1009", "name": "æ˜Œä¹ç»¼åˆé¢‘é“", "alias": "æ˜Œä¹ç»¼åˆ"},
    {"id": "1011", "name": "å¥æ–‡å¨±ä¹é¢‘é“", "alias": "å¥æ–‡å¨±ä¹"}
]
# ==================================================

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class EPGMerger:
    def __init__(self):
        self.session = self._create_session()
        self.channel_ids: Set[str] = set()
        os.makedirs(OUTPUT_DIR, exist_ok=True)

    def _create_session(self) -> requests.Session:
        """åˆ›å»ºå¸¦é‡è¯•çš„ä¼šè¯"""
        session = requests.Session()
        retry = Retry(total=3, backoff_factor=1.5, status_forcelist=[429, 500, 502, 503, 504])
        session.mount("http://", HTTPAdapter(max_retries=retry))
        session.mount("https://", HTTPAdapter(max_retries=retry))
        session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        })
        return session

    def _clean_xml(self, content: str) -> str:
        """æ¸…ç†XMLéæ³•å­—ç¬¦"""
        return re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', content).replace('& ', '&amp; ')

    def _read_config(self) -> List[str]:
        """è¯»å–config.txtä¸­çš„ç½‘ç»œEPGæºï¼ˆæœ€å¤š5æ¡ï¼‰"""
        if not os.path.exists(CONFIG_FILE):
            logging.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CONFIG_FILE}")
            return []
        
        try:
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                sources = [
                    line.strip() for line in f
                    if line.strip() and not line.startswith("#") and line.startswith(("http://", "https://"))
                ]
            # é™åˆ¶æœ€å¤š5æ¡ç½‘ç»œæº
            sources = sources[:5]
            logging.info(f"ä»{CONFIG_FILE}è¯»å–åˆ°{len(sources)}æ¡ç½‘ç»œEPGæº")
            for i, source in enumerate(sources, 1):
                logging.info(f"  {i}. {source[:60]}...")
            return sources
        except Exception as e:
            logging.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
            return []

    def _fetch_network_epg(self, source: str) -> etree._Element:
        """æŠ“å–å•æ¡ç½‘ç»œEPGæº"""
        try:
            logging.info(f"æŠ“å–ç½‘ç»œæº: {source[:60]}...")
            resp = self.session.get(source, timeout=TIMEOUT)
            resp.raise_for_status()
            
            # å¤„ç†GZIPå‹ç¼©
            if source.endswith('.gz'):
                content = gzip.decompress(resp.content).decode('utf-8')
            else:
                content = resp.text
            
            xml_tree = etree.fromstring(self._clean_xml(content).encode('utf-8'))
            logging.info(f"æˆåŠŸæŠ“å–ç½‘ç»œæº: {source[:30]}...")
            return xml_tree
        except Exception as e:
            logging.error(f"æŠ“å–ç½‘ç»œæºå¤±è´¥: {source[:30]}... -> {str(e)[:50]}")
            return etree.Element("tv")  # è¿”å›ç©ºèŠ‚ç‚¹ï¼Œä¸ä¸­æ–­æµç¨‹

    def _process_local_weifang_epg(self) -> etree._Element:
        """è¯»å–å¹¶å¤„ç†æœ¬åœ°æ½åŠEPGæ–‡ä»¶"""
        if not os.path.exists(LOCAL_WEIFANG_EPG):
            logging.warning(f"æœ¬åœ°æ½åŠEPGæ–‡ä»¶ä¸å­˜åœ¨: {LOCAL_WEIFANG_EPG}ï¼Œè·³è¿‡åˆå¹¶")
            return etree.Element("tv")
        
        try:
            logging.info(f"å¼€å§‹åˆå¹¶æœ¬åœ°æ½åŠEPGæ–‡ä»¶: {LOCAL_WEIFANG_EPG}")
            with open(LOCAL_WEIFANG_EPG, "r", encoding="utf-8") as f:
                content = f.read()
            content_clean = self._clean_xml(content)
            xml_tree = etree.fromstring(content_clean.encode('utf-8'))
            logging.info(f"æˆåŠŸè¯»å–æœ¬åœ°æ½åŠEPGæ–‡ä»¶")
            return xml_tree
        except Exception as e:
            logging.error(f"å¤„ç†æœ¬åœ°æ½åŠEPGå¤±è´¥: {str(e)}ï¼Œè·³è¿‡åˆå¹¶")
            return etree.Element("tv")  # è¿”å›ç©ºèŠ‚ç‚¹ï¼Œä¸ä¸­æ–­æµç¨‹

    def _merge_all_epg(self, xml_trees: List[etree._Element]) -> etree._Element:
        """åˆå¹¶æ‰€æœ‰EPGæºï¼ˆç½‘ç»œæº+æœ¬åœ°æºï¼‰"""
        final_root = etree.Element("tv", 
            generator_info_name="EPGåˆå¹¶å™¨ï¼ˆç½‘ç»œ+æœ¬åœ°ï¼‰", 
            last_update=datetime.now().strftime("%Y%m%d%H%M%S")
        )

        # åˆå¹¶é¢‘é“å’ŒèŠ‚ç›®
        for tree in xml_trees:
            # åˆå¹¶é¢‘é“ï¼ˆå»é‡ï¼‰
            for channel in tree.xpath("//channel"):
                channel_id = channel.get("id")
                if channel_id and channel_id not in self.channel_ids:
                    self.channel_ids.add(channel_id)
                    final_root.append(channel)
            # åˆå¹¶èŠ‚ç›®
            for program in tree.xpath("//programme"):
                final_root.append(program)

        return final_root

    def _save_epg(self, xml_root: etree._Element):
        """ä¿å­˜æœ€ç»ˆEPGæ–‡ä»¶"""
        xml_content = etree.tostring(xml_root, encoding="utf-8", pretty_print=True).decode("utf-8")
        
        # ä¿å­˜XMLæ–‡ä»¶
        xml_path = os.path.join(OUTPUT_DIR, "epg.xml")
        with open(xml_path, "w", encoding="utf-8") as f:
            f.write(xml_content)
        
        # ä¿å­˜GZIPå‹ç¼©æ–‡ä»¶
        gz_path = os.path.join(OUTPUT_DIR, "epg.gz")
        with gzip.open(gz_path, "wb") as f:
            f.write(xml_content.encode("utf-8"))

        # ç»Ÿè®¡ä¿¡æ¯
        total_channels = len(self.channel_ids)
        total_programs = len(xml_root.xpath("//programme"))
        logging.info(f"\nğŸ’¾ EPGæ–‡ä»¶ä¿å­˜æˆåŠŸ:")
        logging.info(f"  - æ€»é¢‘é“æ•°: {total_channels}")
        logging.info(f"  - æ€»èŠ‚ç›®æ•°: {total_programs}")
        logging.info(f"  - XMLæ–‡ä»¶: {xml_path}")
        logging.info(f"  - GZIPæ–‡ä»¶: {gz_path}")

    def run(self):
        """ä¸»è¿è¡Œé€»è¾‘"""
        start_time = time.time()
        logging.info("ğŸš€ å¼€å§‹EPGåˆå¹¶æµç¨‹ï¼ˆç½‘ç»œæº+æœ¬åœ°æ½åŠæºï¼‰")

        # 1. è¯»å–ç½‘ç»œæºé…ç½®
        network_sources = self._read_config()
        # 2. æŠ“å–æ‰€æœ‰ç½‘ç»œæº
        network_trees = [self._fetch_network_epg(source) for source in network_sources]
        # 3. è¯»å–æœ¬åœ°æ½åŠEPG
        local_tree = self._process_local_weifang_epg()
        # 4. åˆå¹¶æ‰€æœ‰æºï¼ˆç½‘ç»œæº+æœ¬åœ°æºï¼‰
        all_trees = network_trees + [local_tree]
        final_tree = self._merge_all_epg(all_trees)
        # 5. ä¿å­˜æ–‡ä»¶
        self._save_epg(final_tree)

        logging.info(f"\nâœ… åˆå¹¶æµç¨‹å®Œæˆï¼Œæ€»è€—æ—¶: {time.time() - start_time:.2f}ç§’")
        return True

if __name__ == "__main__":
    merger = EPGMerger()
    merger.run()
