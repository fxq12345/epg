import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime, timedelta
import xml.etree.ElementTree as ET
from xml.dom import minidom
import time
import random

# --- å°è¯•å¯¼å…¥Selenium ---
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    print("â„¹ï¸ æç¤º: æœªå®‰è£…seleniumã€‚è‹¥requestså¤±æ•ˆï¼Œå»ºè®®å®‰è£…ä»¥è·å¾—æ›´é«˜æˆåŠŸç‡ã€‚")

# ===================== é…ç½®åŒº =====================
CHANNELS = [
    ("æ½åŠæ–°é—»é¢‘é“", "https://m.tvsou.com/epg/db502561"),
    ("æ½åŠç»æµç”Ÿæ´»é¢‘é“", "https://m.tvsou.com/epg/47a9d24a"),
    ("æ½åŠç§‘æ•™é¢‘é“", "https://m.tvsou.com/epg/d131d3d1"),
    ("æ½åŠå…¬å…±é¢‘é“", "https://m.tvsou.com/epg/c06f0cc0")
]

WEEK_MAP = {"å‘¨ä¸€": "w1", "å‘¨äºŒ": "w2", "å‘¨ä¸‰": "w3", "å‘¨å››": "w4", "å‘¨äº”": "w5", "å‘¨å…­": "w6", "å‘¨æ—¥": "w7"}

# === å…³é”®é…ç½®ï¼šä½¿ç”¨å¿…åº”æœç´¢ä½œä¸ºRefererï¼Œè§£å†³é˜²ç›—é“¾é—®é¢˜ ===
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Linux; Android 12; Mobile) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Mobile Safari/537.36",
    "Referer": "https://www.bing.com/search?q=%E7%94%B5%E8%A7%86%E8%8A%82%E7%9B%AE%E8%A1%A8" # æ¨¡æ‹Ÿä»å¿…åº”æœç´¢"ç”µè§†èŠ‚ç›®è¡¨"è¿›å…¥
}

# ===================== å·¥å…·å‡½æ•° =====================
def time_to_xmltv(base_date, time_str):
    try:
        hh, mm = time_str.strip().split(":")
        dt = datetime.combine(base_date, datetime.min.time().replace(hour=int(hh), minute=int(mm)))
        return dt.strftime("%Y%m%d%H%M%S +0800")
    except:
        return ""

def get_page_html(url):
    """è·å–ç½‘é¡µå†…å®¹ï¼Œä¼˜å…ˆrequestsï¼Œå¤±è´¥åˆ™å°è¯•Selenium"""
    
    # --- ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šRequests (é€Ÿåº¦å¿«ï¼Œä¸”å·²é…ç½®å¿…åº”Referer) ---
    try:
        print(f"ğŸ“¡ å°è¯•è¯·æ±‚: {url}")
        resp = requests.get(url, headers=HEADERS, timeout=15)
        resp.encoding = 'utf-8'
        html = resp.text
        
        # ç®€å•éªŒè¯ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«èŠ‚ç›®å•å…³é”®è¯
        if "èŠ‚ç›®å•" in html or "èŠ‚ç›®é¢„å‘Š" in html or len(re.findall(r'\d{1,2}:\d{2}', html)) > 5:
            print("âœ… Requests è·å–æˆåŠŸ")
            return html
        else:
            print("âš ï¸ Requests è·å–å†…å®¹æ— æ•ˆï¼Œå‡†å¤‡åˆ‡æ¢Selenium...")
            
    except Exception as e:
        print(f"âŒ Requests é”™è¯¯: {e}")

    # --- ç¬¬äºŒä¼˜å…ˆçº§ï¼šSelenium (æ¨¡æ‹Ÿæµè§ˆå™¨) ---
    if SELENIUM_AVAILABLE:
        print("ğŸ“± å¯åŠ¨Seleniumæ¨¡æ‹Ÿæµè§ˆå™¨...")
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument(f"user-agent={HEADERS['User-Agent']}")
        # å…³é”®ï¼šSeleniumä¹Ÿéœ€è¦è®¾ç½®Refererï¼Œè™½ç„¶è¾ƒéš¾è®¾ç½®ï¼Œä½†æµè§ˆå™¨ç¯å¢ƒæœ¬èº«æ›´å¯ä¿¡
        chrome_options.add_argument("--referer=https://www.bing.com")
        
        try:
            driver = webdriver.Chrome(options=chrome_options)
            driver.get(url)
            time.sleep(3 + random.random()) # éšæœºç­‰å¾…ï¼Œæ¨¡æ‹Ÿäººå·¥
            html = driver.page_source
            driver.quit()
            print("âœ… Selenium è·å–æˆåŠŸ")
            return html
        except Exception as e:
            print(f"âŒ Selenium é”™è¯¯: {e}")
    
    return ""

def get_day_program(channel_name, channel_base_url, week_name, w_suffix):
    # ä¿®æ­£URLæ‹¼æ¥: ç¡®ä¿åŸºç¡€é“¾æ¥å’Œåç¼€ä¹‹é—´æœ‰æ–œæ 
    if channel_base_url.endswith('/'):
        url = f"{channel_base_url}{w_suffix}"
    else:
        url = f"{channel_base_url}/{w_suffix}"
    
    programs = []
    try:
        html = get_page_html(url)
        if not html:
            return programs
            
        soup = BeautifulSoup(html, "html.parser")
        
        # ç­–ç•¥1: æŸ¥æ‰¾å¸¸è§çš„èŠ‚ç›®é¡¹class
        items = soup.find_all("div", class_=re.compile("program-item|time-item", re.I))
        
        if not items: # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾liåˆ—è¡¨
            items = soup.find_all("li")
            
        for item in items:
            item_text = item.get_text(strip=True)
            # ä½¿ç”¨æ­£åˆ™æå–æ—¶é—´+æ ‡é¢˜
            match = re.search(r'(\d{1,2}:\d{2})\s*(.+)', item_text)
            if match:
                t, title = match.groups()
                if len(title) > 1 and 'å¹¿å‘Š' not in title and 'æŠ¥æ—¶' not in title: # è¿‡æ»¤æ— æ•ˆé¡¹
                    programs.append((t.strip(), title.strip()))
        
        # å»é‡å¹¶æ’åº
        programs = sorted(list(set(programs)), key=lambda x: x[0])
        print(f"âœ… {channel_name} - {week_name}: {len(programs)} æ¡")
        
    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥ {week_name}: {e}")
    
    return programs

# ===================== ç”ŸæˆXML =====================
def build_weifang_xml(all_channel_data):
    root = ET.Element("tv")
    root.set("source-info-name", "æ½åŠæœè§†ç½‘EPG")
    
    # 1. ç”Ÿæˆé¢‘é“èŠ‚ç‚¹
    for channel_name, _ in CHANNELS:
        ch = ET.SubElement(root, "channel", id=channel_name)
        ET.SubElement(ch, "display-name", lang="zh").text = channel_name

    # 2. å¡«å……èŠ‚ç›®æ•°æ®
    today = datetime.now()
    monday = today - timedelta(days=today.weekday())

    for channel_name, week_data_list in all_channel_data.items():
        for i, (week_name, w_suffix, progs) in enumerate(week_data_list):
            current_date = monday + timedelta(days=i)
            for idx in range(len(progs)):
                start_time_str, title = progs[idx]
                
                # è®¡ç®—ç»“æŸæ—¶é—´
                if idx < len(progs) - 1:
                    end_time_str = progs[idx+1][0]
                else:
                    end_time_str = (datetime.strptime(start_time_str, "%H:%M") + timedelta(minutes=30)).strftime("%H:%M")
                
                start_xmltv = time_to_xmltv(current_date, start_time_str)
                end_xmltv = time_to_xmltv(current_date, end_time_str)
                
                if start_xmltv and end_xmltv:
                    prog = ET.SubElement(root, "programme")
                    prog.set("start", start_xmltv)
                    prog.set("stop", end_xmltv)
                    prog.set("channel", channel_name)
                    
                    ET.SubElement(prog, "title", lang="zh").text = title
                    ET.SubElement(prog, "desc", lang="zh").text = f"{start_time_str} - {title}"
    
    # æ ¼å¼åŒ–è¾“å‡º
    rough_string = ET.tostring(root, encoding='utf-8')
    reparsed = minidom.parseString(rough_string)
    return reparsed.toprettyxml(indent="  ", encoding="utf-8")

# ===================== ä¸»ç¨‹åº =====================
def main():
    print("="*50)
    print("æ½åŠ4é¢‘é“EPGæŠ“å–å™¨ (å¿…åº”Refererç‰ˆ)")
    print("="*50)
    
    all_channel_data = {}
    
    for channel_name, base_url in CHANNELS:
        print(f"\n{'-'*40}")
        print(f"ğŸ“¡ é¢‘é“: {channel_name}")
        week_data = []
        
        for week_name, w_suffix in WEEK_MAP.items():
            progs = get_day_program(channel_name, base_url, week_name, w_suffix)
            week_data.append((week_name, w_suffix, progs))
            # éšæœºå»¶æ—¶ï¼Œé˜²æ­¢è¢«å°
            time.sleep(1 + random.random() * 2)
            
        all_channel_data[channel_name] = week_data
    
    # ç”Ÿæˆæ–‡ä»¶
    try:
        xml_bytes = build_weifang_xml(all_channel_data)
        with open("weifang_epg.xml", "wb") as f:
            f.write(xml_bytes)
        print(f"\nğŸ‰ æŠ“å–å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜ã€‚")
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
