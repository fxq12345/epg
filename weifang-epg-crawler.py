import requests
from bs4 import BeautifulSoup
import re
from datetime import datetime, timedelta
import xml.etree.ElementTree as ET
from xml.dom import minidom
import time
import random

# å¯é€‰Seleniumæ”¯æŒ
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False

# ===================== é…ç½®åŒº =====================
# é¢‘é“IDä¿®æ”¹ä¸ºç›’å­å…¼å®¹æç®€åç§°ï¼Œå½»åº•è§£å†³è¯†åˆ«ä¸ºç©º
CHANNELS = [
    ("æ½åŠæ–°é—»", "https://m.tvsou.com/epg/db502561"),
    ("æ½åŠç»æµ", "https://m.tvsou.com/epg/47a9d24a"),
    ("æ½åŠç§‘æ•™", "https://m.tvsou.com/epg/d131d3d1"),
    ("æ½åŠå…¬å…±", "https://m.tvsou.com/epg/c06f0cc0")
]

WEEK_MAP = {
    "å‘¨ä¸€": "w1",
    "å‘¨äºŒ": "w2",
    "å‘¨ä¸‰": "w3",
    "å‘¨å››": "w4",
    "å‘¨äº”": "w5",
    "å‘¨å…­": "w6",
    "å‘¨æ—¥": "w7"
}

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Linux; Android 12; Mobile) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Mobile Safari/537.36",
    "Referer": "https://www.bing.com/search?q=%E7%94%B5%E8%A7%86%E8%8A%82%E7%9B%AE%E8%A1%A8"
}

# ===================== å·¥å…·å‡½æ•° =====================
def time_to_xmltv(base_date, time_str):
    try:
        hh, mm = time_str.strip().split(":")
        dt = datetime.combine(base_date, datetime.min.time().replace(hour=int(hh), minute=int(mm)))
        return dt.strftime("%Y%m%d%H%M%S +0800")
    except:
        return ""

def get_page_html(url):
    try:
        print(f"ğŸ“¡ è¯·æ±‚: {url}")
        resp = requests.get(url, headers=HEADERS, timeout=20)
        resp.encoding = 'utf-8'
        html = resp.text
        if "èŠ‚ç›®å•" in html or "èŠ‚ç›®é¢„å‘Š" in html or len(re.findall(r'\d{1,2}:\d{2}', html)) > 5:
            print("âœ… Requests æˆåŠŸ")
            return html
        else:
            print("âš ï¸ å†…å®¹å¼‚å¸¸ï¼Œåˆ‡æ¢å¤‡ç”¨æ¨¡å¼")
    except Exception as e:
        print(f"âŒ Requests å¤±è´¥: {e}")

    if SELENIUM_AVAILABLE:
        try:
            chrome_options = Options()
            chrome_options.add_argument("--headless=new")
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument(f"user-agent={HEADERS['User-Agent']}")
            driver = webdriver.Chrome(options=chrome_options)
            driver.get(url)
            time.sleep(3 + random.random())
            html = driver.page_source
            driver.quit()
            print("âœ… Selenium æˆåŠŸ")
            return html
        except Exception as e:
            print(f"âŒ Selenium å¤±è´¥: {e}")
    return ""

def get_day_program(channel_name, channel_base_url, week_name, w_suffix):
    if channel_base_url.endswith('/'):
        url = f"{channel_base_url}{w_suffix}"
    else:
        url = f"{channel_base_url}/{w_suffix}"

    programs = []
    try:
        html = get_page_html(url)
        if not html:
            return programs

        soup = BeautifulSoup(html, "html.parser")
        items = soup.find_all("div", class_=re.compile("program-item|time-item", re.I))
        if not items:
            items = soup.find_all("li")

        for item in items:
            text = item.get_text(strip=True)
            match = re.search(r'(\d{1,2}:\d{2})\s*(.+)', text)
            if match:
                t, title = match.groups()
                if len(title) > 1 and 'å¹¿å‘Š' not in title and 'æŠ¥æ—¶' not in title:
                    programs.append((t.strip(), title.strip()))

        programs = sorted(list(set(programs)), key=lambda x: x[0])
        print(f"âœ… {channel_name} {week_name}: {len(programs)} æ¡")
    except Exception as e:
        print(f"âŒ {week_name} å¼‚å¸¸: {e}")
    return programs

# ===================== æœºé¡¶ç›’å…¨å…¼å®¹XMLç”Ÿæˆï¼ˆä¿®å¤è¯†åˆ«ä¸ºç©ºï¼‰ =====================
def build_weifang_xml(all_channel_data):
    root = ET.Element("tv")
    root.set("source-info-name", "WeifangEPG")
    root.set("generator", "WeifangAutoCrawler")

    # å†™å…¥æ ‡å‡†é¢‘é“èŠ‚ç‚¹ï¼Œåç§°æç®€ï¼Œå…¨è®¾å¤‡å…¼å®¹
    for channel_name, _ in CHANNELS:
        ch = ET.SubElement(root, "channel", id=channel_name)
        display = ET.SubElement(ch, "display-name")
        display.text = channel_name

    today = datetime.now()
    monday = today - timedelta(days=today.weekday())

    for channel_name, week_data_list in all_channel_data.items():
        for i, (week_name, w_suffix, progs) in enumerate(week_data_list):
            current_date = monday + timedelta(days=i)
            for idx in range(len(progs)):
                start_time_str, title = progs[idx]
                if idx < len(progs) - 1:
                    end_time_str = progs[idx+1][0]
                else:
                    end_time_str = (datetime.strptime(start_time_str, "%H:%M") + timedelta(minutes=30)).strftime("%H:%M")

                start_xml = time_to_xmltv(current_date, start_time_str)
                end_xml = time_to_xmltv(current_date, end_time_str)
                if start_xml and end_xml and title:
                    prog = ET.SubElement(root, "programme")
                    prog.set("start", start_xml)
                    prog.set("stop", end_xml)
                    prog.set("channel", channel_name)
                    
                    title_node = ET.SubElement(prog, "title")
                    title_node.text = title
                    desc_node = ET.SubElement(prog, "desc")
                    desc_node.text = title

    # æ ‡å‡†XMLå¤´ï¼Œå¼ºåˆ¶utf-8ï¼Œæœºé¡¶ç›’100%è¯†åˆ«
    rough_string = ET.tostring(root, encoding='utf-8')
    reparsed = minidom.parseString(rough_string)
    xml_output = reparsed.toprettyxml(indent="  ", encoding='utf-8').decode('utf-8')
    # æ›¿æ¢ä¸ºç©ºè¡Œï¼Œä¿®å¤æ ¼å¼å…¼å®¹é—®é¢˜
    xml_output = xml_output.replace('<?xml version="1.0" ?>', '<?xml version="1.0" encoding="UTF-8"?>')
    return xml_output.encode('utf-8')

# ===================== ä¸»ç¨‹åº =====================
def main():
    print("="*60)
    print("ğŸš€ æ½åŠ4é¢‘é“ EPG æŠ“å–ï¼ˆæœºé¡¶ç›’å…¼å®¹ä¿®å¤ç‰ˆï¼‰")
    print("="*60)

    all_channel_data = {}
    for channel_name, base_url in CHANNELS:
        print(f"\n--- {channel_name} ---")
        week_data = []
        for week_name, w_suffix in WEEK_MAP.items():
            progs = get_day_program(channel_name, base_url, week_name, w_suffix)
            week_data.append((week_name, w_suffix, progs))
            time.sleep(1 + random.random()*1.5)
        all_channel_data[channel_name] = week_data

    # å…œåº•ç”Ÿæˆæ ‡å‡†XMLï¼Œç»å¯¹ä¸ä¼šè¢«è¯†åˆ«ä¸ºç©º
    try:
        xml_bytes = build_weifang_xml(all_channel_data)
    except Exception:
        xml_str = '''<?xml version="1.0" encoding="UTF-8"?>
<tv source-info-name="WeifangEPG">
<channel id="æ½åŠæ–°é—»"><display-name>æ½åŠæ–°é—»</display-name></channel>
<channel id="æ½åŠç»æµ"><display-name>æ½åŠç»æµ</display-name></channel>
<channel id="æ½åŠç§‘æ•™"><display-name>æ½åŠç§‘æ•™</display-name></channel>
<channel id="æ½åŠå…¬å…±"><display-name>æ½åŠå…¬å…±</display-name></channel>
</tv>'''
        xml_bytes = xml_str.encode('utf-8')

    try:
        with open("weifang_4channels_epg.xml", "wb") as f:
            f.write(xml_bytes)
        print("\nâœ… å…¼å®¹ç‰ˆXMLå·²å†™å…¥ï¼Œç›’å­å¯æ­£å¸¸è¯†åˆ«ï¼")
    except Exception as e:
        print(f"\nâŒ å†™å…¥å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
